{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Content Extraction Using Generative AI  \n",
    " This notebook is designed to be user-friendly, even for those with minimal technical background.  \n",
    "   \n",
    "## Instructions:  \n",
    "   \n",
    "1. **Install Libraries and Dependencies:**  \n",
    "   - Before running the cells, make sure that all required libraries are installed. This might involve installing packages via pip or conda. Typically, you would use a command like `pip install -r requirements.txt` in your terminal, where `requirements.txt` is a file containing a list of items to be installed.  \n",
    "   \n",
    "2. **Run Each Cell:**  \n",
    "   - Start from the top and run each cell in order by clicking on the cell and pressing the \"Run\" button or using the shortcut `Shift + Enter`. Make sure to run them sequentially as some cells depend on the output of the previous cells.  \n",
    "   \n",
    "3. **Enter Required Information:**  \n",
    "   - If the notebook requires any inputs (like image URLs or project IDs), make sure to enter them when prompted.  \n",
    "   \n",
    "4. **View Results:**  \n",
    "   - After running the cells related to the AI model invocation, you should see the output below those cells. This output will provide insights into the content of the image based on the AI's analysis.  \n",
    "   \n",
    "Feel free to modify the inputs or experiment with different images to see how the model's responses change. Enjoy exploring the capabilities of generative AI in visual content understanding!  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv(\".env\", override=True)\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from google.cloud import bigquery\n",
    "import tqdm\n",
    "\n",
    "from PIL import Image  \n",
    "from io import BytesIO  \n",
    "from IPython.display import Markdown, Video, display\n",
    "\n",
    "from google.cloud import storage\n",
    "from PIL import Image  # Using PIL for image manipulation\n",
    "\n",
    "\n",
    "from pydantic import BaseModel, Field, constr, field_validator  \n",
    "\n",
    "# Pandas display options\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.max_colwidth', None)  \n",
    "\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from pydantic import BaseModel, Field, constr, field_validator  \n",
    "from typing import List, Union\n",
    "from typing_extensions import Literal\n",
    "import json \n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "client = bigquery.Client(os.getenv(\"PROJECT_ID\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_pillow(gcs_url):\n",
    "\n",
    "    image = Image.open(BytesIO(image_to_bytes(gcs_url)))\n",
    "    return image\n",
    "\n",
    "def image_to_bytes(gcs_url):\n",
    "    \"\"\"Loads an image from Google Cloud Storage and returns a PIL Image object.\n",
    "    Args:\n",
    "        gcs_url (str): Full GCS URL of the image (e.g., \"gs://bucket/image.jpg\").\n",
    "    Returns:\n",
    "        PIL.Image.Image: PIL Image object, or None if an error occurred.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        bucket_name, blob_name = gcs_url.replace(\"gs://\", \"\").split(\"/\")[-2:]\n",
    "        client = storage.Client(os.getenv(\"PROJECT_ID\"))\n",
    "        bucket = client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        image_bytes = blob.download_as_bytes()\n",
    "        return image_bytes\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image from GCS: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genai_client = genai.Client(\n",
    "    vertexai=True, project=os.getenv(\"PROJECT_ID\"), location='us-central1'\n",
    ")\n",
    "\n",
    "IMAGE_LINK=\"https://storage.googleapis.com/ds-genai-test-renault-ad-lib-image/ea6e9608-e4bd-4a75-bb6d-9d983ced68f8.jpg\"\n",
    "\n",
    "image_to_pillow(IMAGE_LINK)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bastien --> mettre en place un code de test pour le prompting\n",
    "bytes = image_to_bytes(IMAGE_LINK)\n",
    "\n",
    "class ImageInformationTest(BaseModel):  \n",
    "    \"\"\"Information about an image.\"\"\"  \n",
    "\n",
    "    promotion_display: bool = Field(description=\"\"\"\n",
    "                Indicates whether a currency is displayed in the ad. True if 'yes', False if 'no'.\n",
    "                exemples: \n",
    "                    - 100%: False\n",
    "                    - 100â‚¬: True             \n",
    "            \"\"\") \n",
    "    call_to_action_verb: str = Field(default=\"None\", description=\"The specific verb used in the call to action, if present (e.g., 'buy', 'test').\")  \n",
    "    promotion_wording_type: Literal[\"None\", \"gain\", \"loss_aversion\"] = Field(default=\"None\", description=\"Specifies the type of promotion wording used in the ad: 'gain' for emphasizing benefits, 'loss_aversion' for emphasizing avoidance of loss, or 'None' if there is no promotion wording.\")  \n",
    "\n",
    "response = genai_client.models.generate_content(\n",
    "    model='gemini-2.0-flash-exp', \n",
    "    contents=[\n",
    "        'Describe the content of the picture',\n",
    "        types.Part.from_bytes(data=bytes, mime_type=\"image/png\")    \n",
    "    ],\n",
    "    config=types.GenerateContentConfig(\n",
    "        temperature=0,\n",
    "        response_mime_type= 'application/json',\n",
    "        response_schema= ImageInformationTest\n",
    "    )\n",
    ")\n",
    "\n",
    "feature_dict = json.loads(response.text)\n",
    "print(\"=\"*10,\"response\", \"=\"*10)\n",
    "pprint.pprint(feature_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
